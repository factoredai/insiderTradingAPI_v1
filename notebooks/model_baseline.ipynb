{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pickle as pkl\n",
    "import os\n",
    "import finviz as fz\n",
    "import yfinance as yf\n",
    "import calendar\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_year(current_month, current_year):\n",
    "    dict_cont = {}\n",
    "    dict_cont[\"current_year\"] = current_year\n",
    "    dict_cont[\"previous_month\"] = current_month\n",
    "    def _infer_year(x):\n",
    "        delta_months = dict_cont[\"previous_month\"] - x\n",
    "        if x>=1 and delta_months>=0:\n",
    "            dict_cont[\"current_year\"]\n",
    "            dict_cont[\"previous_month\"] = x\n",
    "        else:\n",
    "            dict_cont[\"previous_month\"] = x\n",
    "            dict_cont[\"current_year\"]-=1\n",
    "        return dict_cont[\"current_year\"]\n",
    "    return _infer_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_space = 0.8\n",
    "perc_time = 0.8\n",
    "\n",
    "WINDOW_SIZE = 21 # Include window + target\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "sp_100_file = os.path.join(data_path, \"sp-100-index-07-02-2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_100_df = pd.read_csv(sp_100_file)\n",
    "simbols = sp_100_df.Symbol.values[:-1]\n",
    "map_month2month_number = dict((v,k) for k,v in enumerate(calendar.month_abbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BKNG <class 'IndexError'> list index out of range\n",
      "BRK.B <class 'requests.exceptions.HTTPError'> 404 Client Error: Not Found for url: https://finviz.com/quote.ashx?t=BRK.B\n",
      "C <class 'IndexError'> list index out of range\n",
      "DD <class 'IndexError'> list index out of range\n",
      "EXC <class 'IndexError'> list index out of range\n",
      "GOOGL <class 'IndexError'> list index out of range\n",
      "GS <class 'IndexError'> list index out of range\n",
      "MO <class 'IndexError'> list index out of range\n",
      "RTX <class 'IndexError'> list index out of range\n"
     ]
    }
   ],
   "source": [
    "stock = {}\n",
    "cont = 0\n",
    "for simbol in simbols:\n",
    "    try:\n",
    "        insider_info = fz.get_insider(simbol)\n",
    "        insider_data = pd.DataFrame.from_dict(insider_info)\n",
    "        insider_data[[\"month_name\", \"day\"]]= insider_data.Date.str.split(\" \", expand=True)\n",
    "        insider_data[\"month\"] = insider_data[\"month_name\"].map(map_month2month_number)\n",
    "        insider_data[\"year\"] = insider_data[\"month\"].apply(infer_year(datetime.datetime.now().month,\n",
    "                                                                      datetime.datetime.now().year))\n",
    "        insider_data[\"date\"] = pd.to_datetime(insider_data[[\"year\", \"month\", \"day\"]], format=\"%y%m%d\") \n",
    "        cont = cont + 1\n",
    "    except Exception as inst:\n",
    "        print(simbol, end=\" \")\n",
    "        print(type(inst), end=\" \")# the exception instance\n",
    "        print(inst) \n",
    "        continue\n",
    "    curr_ticker = yf.Ticker(simbol)\n",
    "    curr_hist = curr_ticker.history(period=\"1y\")\n",
    "    curr_table = pd.pivot_table(insider_data,\n",
    "                                index=['date'],\n",
    "                                columns=['Transaction'], aggfunc={\"Transaction\": len})\n",
    "    curr_table = ~curr_table.isnull()\n",
    "    curr_table.columns = [col[1] for col in curr_table.columns]\n",
    "    curr_hist = curr_hist.merge(curr_table, how=\"left\", left_index=True, right_index=True)\n",
    "    curr_hist = curr_hist.fillna(False)\n",
    "    if \"Buy\" not in curr_hist.columns:\n",
    "        curr_hist[\"Buy\"] = False\n",
    "    if \"Sale\" not in curr_hist.columns:\n",
    "        curr_hist[\"Sale\"] = False\n",
    "    if \"Option Exercise\" not in curr_hist.columns:\n",
    "        curr_hist[\"Option Exercise\"] = False\n",
    "    stock[simbol] = curr_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating frames for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_space = int(len(stock.keys())*perc_space)\n",
    "n_train_out_space = len(stock.keys())-n_train_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_space = np.random.choice(list(stock.keys()), size=n_train_space, replace=False).tolist()\n",
    "test_space = list(set(stock.keys()) - set(train_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = stock[train_space[0]].index.min()\n",
    "max_date = stock[train_space[0]].index.max()\n",
    "samples = curr_hist.shape[0]\n",
    "train_samples = int((samples-WINDOW_SIZE)*perc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company:  CSCO\n",
      "Company:  AMT\n",
      "Company:  HON\n",
      "Company:  V\n",
      "Company:  T\n",
      "Company:  MDLZ\n",
      "Company:  DUK\n",
      "Company:  SO\n",
      "Company:  XOM\n",
      "Company:  PG\n",
      "Company:  CAT\n",
      "Company:  AIG\n",
      "Company:  LOW\n",
      "Company:  EMR\n",
      "Company:  COF\n",
      "Company:  JNJ\n",
      "Company:  ACN\n",
      "Company:  MCD\n",
      "Company:  GD\n",
      "Company:  GILD\n",
      "Company:  DIS\n",
      "Company:  PM\n",
      "Company:  MET\n",
      "Company:  GM\n",
      "Company:  GE\n",
      "Company:  LLY\n",
      "Company:  MSFT\n",
      "Company:  TXN\n",
      "Company:  AAPL\n",
      "Company:  NKE\n",
      "Company:  UPS\n",
      "Company:  MMM\n",
      "Company:  MA\n",
      "Company:  QCOM\n",
      "Company:  PFE\n",
      "Company:  BMY\n",
      "Company:  ABBV\n",
      "Company:  BA\n",
      "Company:  COP\n",
      "Company:  COST\n",
      "Company:  MDT\n",
      "Company:  LMT\n",
      "Company:  NFLX\n",
      "Company:  NEE\n",
      "Company:  DHR\n",
      "Company:  PYPL\n",
      "Company:  TMO\n",
      "Company:  DOW\n",
      "Company:  CHTR\n",
      "Company:  BK\n",
      "Company:  KO\n",
      "Company:  MS\n",
      "Company:  CVX\n",
      "Company:  AXP\n",
      "Company:  FB\n",
      "Company:  F\n",
      "Company:  BAC\n",
      "Company:  VZ\n",
      "Company:  USB\n",
      "Company:  UNP\n",
      "Company:  TGT\n",
      "Company:  BIIB\n",
      "Company:  NVDA\n",
      "Company:  CVS\n",
      "Company:  CRM\n",
      "Company:  ORCL\n",
      "Company:  CMCSA\n",
      "Company:  OXY\n",
      "Company:  FDX\n",
      "Company:  SLB\n",
      "Company:  BLK\n",
      "Company:  KHC\n",
      "Company:  SBUX\n",
      "Company:  SPG\n",
      "Company:  JPM\n",
      "Company:  CL\n",
      "Company:  AMZN\n",
      "Company:  GOOG\n",
      "Company:  KMI\n",
      "Company:  MRK\n",
      "Company:  UNH\n",
      "Company:  WMT\n",
      "Company:  PEP\n",
      "Company:  AMGN\n",
      "Company:  WBA\n",
      "Company:  IBM\n",
      "Company:  WFC\n",
      "Company:  INTC\n",
      "Company:  ADBE\n",
      "Company:  ABT\n",
      "Company:  ALL\n",
      "Company:  HD\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "test_datasets = []\n",
    "for company in train_space:\n",
    "    print(\"Company: \", company)\n",
    "    curr_hist = stock[company]\n",
    "    assert min_date == curr_hist.index.min()\n",
    "    assert max_date == curr_hist.index.max()\n",
    "    assert len(curr_hist) == samples\n",
    "    stock[company] = stock[company].astype({'Open': np.float64,\n",
    "                         'High': np.float64,\n",
    "                         'Low': np.float64,\n",
    "                         'Close': np.float64,\n",
    "                         'Volume': np.float64,\n",
    "                         'Dividends': np.float64,\n",
    "                         'Stock Splits': np.float64,\n",
    "                         'Buy': np.float64,\n",
    "                         'Option Exercise': np.float64,\n",
    "                         'Sale': np.float64})\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(stock[company])\n",
    "    dataset = dataset.window(WINDOW_SIZE, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(WINDOW_SIZE))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1:, -3:]))\n",
    "    train_datasets.append(dataset.take(train_samples))\n",
    "    valid_datasets.append(dataset.skip(train_samples))\n",
    "    \n",
    "for company in test_space:\n",
    "    print(\"Company: \", company)\n",
    "    curr_hist = stock[company]\n",
    "    assert min_date == curr_hist.index.min()\n",
    "    assert max_date == curr_hist.index.max()\n",
    "    assert len(curr_hist) == samples\n",
    "    stock[company] = stock[company].astype({'Open': np.float64,\n",
    "                         'High': np.float64,\n",
    "                         'Low': np.float64,\n",
    "                         'Close': np.float64,\n",
    "                         'Volume': np.float64,\n",
    "                         'Dividends': np.float64,\n",
    "                         'Stock Splits': np.float64,\n",
    "                         'Buy': np.float64,\n",
    "                         'Option Exercise': np.float64,\n",
    "                         'Sale': np.float64})\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(stock[company])\n",
    "    dataset = dataset.window(WINDOW_SIZE, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(WINDOW_SIZE))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1:, -3:]))\n",
    "    test_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = None\n",
    "val_ds = None\n",
    "for sample in zip(train_datasets, valid_datasets):\n",
    "    if train_ds is None:\n",
    "        train_ds = sample[0]\n",
    "        val_ds = sample[1]\n",
    "    else:\n",
    "        train_ds = train_ds.concatenate(sample[0])\n",
    "        val_ds = val_ds.concatenate(sample[1])\n",
    "        \n",
    "test_ds = None\n",
    "for sample in test_datasets:\n",
    "    if test_ds is None:\n",
    "        test_ds = sample\n",
    "    else:\n",
    "        test_ds = test_ds.concatenate(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=5000)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(20,10))\n",
    "    x = tf.keras.layers.BatchNormalization(axis=2)(inputs)\n",
    "    x = tf.keras.layers.GRU(64, return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    sigmoids = tf.keras.layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "    outputs = tf.keras.backend.expand_dims(sigmoids, axis=1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1679/1679 [==============================] - 20s 12ms/step - loss: 0.1300 - accuracy: 0.2029 - auc: 0.6885 - val_loss: 0.1127 - val_accuracy: 0.1450 - val_auc: 0.7760\n",
      "Epoch 2/3\n",
      "1679/1679 [==============================] - 20s 12ms/step - loss: 0.1155 - accuracy: 0.2354 - auc: 0.7510 - val_loss: 0.1126 - val_accuracy: 0.4384 - val_auc: 0.7861\n",
      "Epoch 3/3\n",
      "1679/1679 [==============================] - 20s 12ms/step - loss: 0.1134 - accuracy: 0.2788 - auc: 0.7722 - val_loss: 0.1136 - val_accuracy: 0.2126 - val_auc: 0.7973\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "          validation_data=val_ds,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551/551 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.2418 - auc: 0.7367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12914402782917023, 0.24183303117752075, 0.7366621494293213]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing predictions and looking if it is learning anything\n",
    "dataframe start from the 20, example df[20:] are all the samples in test, and each company has 232 records, so to iterate would be accooording to 232 and addding 20 to the origiinal df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame(np.squeeze(out), columns=[\"Buy\", \"Sell\", \"Option Exercise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buy</th>\n",
       "      <th>Sell</th>\n",
       "      <th>Option Exercise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024702</td>\n",
       "      <td>0.028202</td>\n",
       "      <td>0.010897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024804</td>\n",
       "      <td>0.028381</td>\n",
       "      <td>0.010907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024806</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.010942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.028293</td>\n",
       "      <td>0.010982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.028150</td>\n",
       "      <td>0.010990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>0.006112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>0.030004</td>\n",
       "      <td>0.026465</td>\n",
       "      <td>0.005328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>0.027716</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.007454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>0.027727</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.007455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Buy      Sell  Option Exercise\n",
       "0     0.024702  0.028202         0.010897\n",
       "1     0.024804  0.028381         0.010907\n",
       "2     0.024806  0.028279         0.010942\n",
       "3     0.024803  0.028293         0.010982\n",
       "4     0.024673  0.028150         0.010990\n",
       "...        ...       ...              ...\n",
       "4403  0.028713  0.025139         0.006112\n",
       "4404  0.028839  0.025163         0.005657\n",
       "4405  0.030004  0.026465         0.005328\n",
       "4406  0.027716  0.025217         0.007454\n",
       "4407  0.027727  0.025127         0.007455\n",
       "\n",
       "[4408 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company:  SPG\n"
     ]
    }
   ],
   "source": [
    "for company in test_space:\n",
    "    print(\"Company: \", company)\n",
    "    curr_hist = stock[company]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 10), dtype=float64, numpy=\n",
       "array([[1.5617e+02, 1.5829e+02, 1.5617e+02, 1.5740e+02, 1.4985e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5711e+02, 1.5834e+02, 1.5661e+02, 1.5764e+02, 2.7127e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5827e+02, 1.5855e+02, 1.5645e+02, 1.5701e+02, 1.5552e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5693e+02, 1.5795e+02, 1.5494e+02, 1.5574e+02, 1.0114e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5599e+02, 1.5620e+02, 1.5521e+02, 1.5546e+02, 8.4480e+05,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5574e+02, 1.5704e+02, 1.5528e+02, 1.5579e+02, 1.0197e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5550e+02, 1.5634e+02, 1.5492e+02, 1.5523e+02, 1.1554e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5586e+02, 1.5627e+02, 1.5289e+02, 1.5343e+02, 1.1099e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5364e+02, 1.5364e+02, 1.5221e+02, 1.5271e+02, 2.1525e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5279e+02, 1.5351e+02, 1.4969e+02, 1.4988e+02, 1.7907e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.4989e+02, 1.5038e+02, 1.4854e+02, 1.4863e+02, 1.6029e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.4900e+02, 1.5175e+02, 1.4899e+02, 1.5162e+02, 2.7577e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5226e+02, 1.5291e+02, 1.5142e+02, 1.5250e+02, 1.0547e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5226e+02, 1.5310e+02, 1.5062e+02, 1.5169e+02, 1.1490e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5218e+02, 1.5273e+02, 1.5023e+02, 1.5170e+02, 1.5566e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5213e+02, 1.5419e+02, 1.5213e+02, 1.5295e+02, 1.0428e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5280e+02, 1.5401e+02, 1.5277e+02, 1.5350e+02, 1.3856e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5569e+02, 1.5757e+02, 1.5383e+02, 1.5540e+02, 2.4816e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5426e+02, 1.5465e+02, 1.5077e+02, 1.5088e+02, 2.4410e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.5080e+02, 1.5337e+02, 1.5018e+02, 1.5258e+02, 1.1136e+06,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Buy</th>\n",
       "      <th>Sale</th>\n",
       "      <th>Option Exercise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>151.38</td>\n",
       "      <td>152.24</td>\n",
       "      <td>146.43</td>\n",
       "      <td>148.27</td>\n",
       "      <td>2052700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>148.55</td>\n",
       "      <td>149.42</td>\n",
       "      <td>146.73</td>\n",
       "      <td>147.03</td>\n",
       "      <td>1628300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-07</th>\n",
       "      <td>146.59</td>\n",
       "      <td>148.56</td>\n",
       "      <td>144.48</td>\n",
       "      <td>147.09</td>\n",
       "      <td>1792900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-08</th>\n",
       "      <td>147.31</td>\n",
       "      <td>148.88</td>\n",
       "      <td>146.03</td>\n",
       "      <td>148.65</td>\n",
       "      <td>1235500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>148.46</td>\n",
       "      <td>149.28</td>\n",
       "      <td>147.37</td>\n",
       "      <td>148.46</td>\n",
       "      <td>1229100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>62.64</td>\n",
       "      <td>68.18</td>\n",
       "      <td>61.29</td>\n",
       "      <td>68.13</td>\n",
       "      <td>9412900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>71.36</td>\n",
       "      <td>71.50</td>\n",
       "      <td>67.57</td>\n",
       "      <td>68.38</td>\n",
       "      <td>10456500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>69.80</td>\n",
       "      <td>72.93</td>\n",
       "      <td>69.24</td>\n",
       "      <td>69.81</td>\n",
       "      <td>7979600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>71.81</td>\n",
       "      <td>72.96</td>\n",
       "      <td>68.68</td>\n",
       "      <td>68.81</td>\n",
       "      <td>6470600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>69.72</td>\n",
       "      <td>70.59</td>\n",
       "      <td>67.01</td>\n",
       "      <td>68.93</td>\n",
       "      <td>6069000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close      Volume  Dividends  \\\n",
       "Date                                                                \n",
       "2019-08-05  151.38  152.24  146.43  148.27   2052700.0        0.0   \n",
       "2019-08-06  148.55  149.42  146.73  147.03   1628300.0        0.0   \n",
       "2019-08-07  146.59  148.56  144.48  147.09   1792900.0        0.0   \n",
       "2019-08-08  147.31  148.88  146.03  148.65   1235500.0        0.0   \n",
       "2019-08-09  148.46  149.28  147.37  148.46   1229100.0        0.0   \n",
       "...            ...     ...     ...     ...         ...        ...   \n",
       "2020-06-29   62.64   68.18   61.29   68.13   9412900.0        0.0   \n",
       "2020-06-30   71.36   71.50   67.57   68.38  10456500.0        0.0   \n",
       "2020-07-01   69.80   72.93   69.24   69.81   7979600.0        0.0   \n",
       "2020-07-02   71.81   72.96   68.68   68.81   6470600.0        0.0   \n",
       "2020-07-06   69.72   70.59   67.01   68.93   6069000.0        0.0   \n",
       "\n",
       "            Stock Splits  Buy  Sale  Option Exercise  \n",
       "Date                                                  \n",
       "2019-08-05           0.0  0.0   0.0              0.0  \n",
       "2019-08-06           0.0  0.0   0.0              0.0  \n",
       "2019-08-07           0.0  0.0   0.0              0.0  \n",
       "2019-08-08           0.0  0.0   0.0              0.0  \n",
       "2019-08-09           0.0  0.0   0.0              0.0  \n",
       "...                  ...  ...   ...              ...  \n",
       "2020-06-29           0.0  0.0   0.0              0.0  \n",
       "2020-06-30           0.0  0.0   0.0              0.0  \n",
       "2020-07-01           0.0  0.0   0.0              0.0  \n",
       "2020-07-02           0.0  0.0   0.0              0.0  \n",
       "2020-07-06           0.0  0.0   0.0              0.0  \n",
       "\n",
       "[232 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_hist[20:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:insider]",
   "language": "python",
   "name": "conda-env-insider-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
