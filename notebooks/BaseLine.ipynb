{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pickle as pkl\n",
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "import finviz as fz\n",
    "import yfinance as yf\n",
    "import calendar\n",
    "import datetime\n",
    "import numpy as np\n",
    "from data_layer import data_layer\n",
    "from data_set import get_data_set_train\n",
    "from data_set import get_data_set_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_space = 0.8\n",
    "perc_time = 0.8\n",
    "\n",
    "WINDOW_SIZE = 21 # Include window + target\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "sp_100_file = os.path.join(data_path, \"sp-100-index-07-02-2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BKNG <class 'IndexError'> list index out of range\n",
      "BRK.B <class 'requests.exceptions.HTTPError'> 404 Client Error: Not Found for url: https://finviz.com/quote.ashx?t=BRK.B\n",
      "C <class 'IndexError'> list index out of range\n",
      "DD <class 'IndexError'> list index out of range\n",
      "EXC <class 'IndexError'> list index out of range\n",
      "GOOGL <class 'IndexError'> list index out of range\n",
      "GS <class 'IndexError'> list index out of range\n",
      "MO <class 'IndexError'> list index out of range\n",
      "RTX <class 'IndexError'> list index out of range\n"
     ]
    }
   ],
   "source": [
    "stock = data_layer(sp_100_file, data_path, perc_space, perc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_space = int(len(stock.keys())*perc_space)\n",
    "n_train_out_space = len(stock.keys())-n_train_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_space = np.random.choice(list(stock.keys()), size=n_train_space, replace=False).tolist()\n",
    "test_space = list(set(stock.keys()) - set(train_space))\n",
    "samples = stock[\"AAPL\"].shape[0]\n",
    "train_samples = int((samples-WINDOW_SIZE)*perc_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies:  ['PM', 'AMGN', 'WFC', 'EMR', 'GD', 'QCOM', 'GILD', 'CRM', 'HD', 'KO', 'BK', 'AMT', 'ACN', 'KHC', 'DIS', 'PFE', 'TGT', 'BAC', 'LLY', 'GE', 'VZ', 'OXY', 'MCD', 'MSFT', 'BMY', 'ABBV', 'DUK', 'IBM', 'UPS', 'PEP', 'AAPL', 'BA', 'MET', 'CSCO', 'NKE', 'CHTR', 'F', 'SBUX', 'JPM', 'FDX', 'COF', 'MDT', 'UNH', 'LOW', 'TMO', 'ALL', 'BLK', 'T', 'MRK', 'MDLZ', 'HON', 'AMZN', 'INTC', 'JNJ', 'NEE', 'SO', 'DHR', 'UNP', 'FB', 'XOM', 'AXP', 'WMT', 'CVS', 'SLB', 'CAT', 'NFLX', 'TXN', 'MMM', 'BIIB', 'KMI', 'COST', 'ORCL', 'AIG']\n",
      "Companies:  ['CL', 'NVDA', 'ADBE', 'DOW', 'GOOG', 'SPG', 'ABT', 'USB', 'MS', 'GM', 'CMCSA', 'MA', 'CVX', 'LMT', 'V', 'COP', 'PYPL', 'PG', 'WBA']\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = get_data_set_train(WINDOW_SIZE,stock,train_space,train_samples)\n",
    "test_ds = get_data_set_test(WINDOW_SIZE,stock,test_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=5000)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(20,10))\n",
    "    x = tf.keras.layers.BatchNormalization(axis=2)(inputs)\n",
    "    x = tf.keras.layers.GRU(64, return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    sigmoids = tf.keras.layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "    outputs = tf.keras.backend.expand_dims(sigmoids, axis=1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6260 - accuracy: 0.8324 - AUC: 0.3623 - val_loss: 0.8263 - val_accuracy: 0.6667 - val_AUC: 0.0000e+00\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.2278 - accuracy: 0.9892 - AUC: 0.6547 - val_loss: 0.3875 - val_accuracy: 1.0000 - val_AUC: 0.0000e+00\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0387 - accuracy: 0.9928 - AUC: 0.7704 - val_loss: 0.1751 - val_accuracy: 1.0000 - val_AUC: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "          validation_data=val_ds,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing predictions and looking if it is learning anything\n",
    "dataframe start from the 20, example df[20:] are all the samples in test, and each company has 232 records, so to iterate would be accooording to 232 and addding 20 to the origiinal df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_ds)\n",
    "predicted_df = pd.DataFrame(np.squeeze(out), columns=[\"Buy\", \"Sell\", \"Option Exercise\"])\n",
    "for company in test_space:\n",
    "    print(\"Company: \", company)\n",
    "    curr_hist = stock[company]\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
